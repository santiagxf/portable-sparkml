{"cells":[{"cell_type":"code","source":["# IGNORE THIS CELL\nimport os\n\nbasepath = \"/mnt/azureblob\"\n\nif basepath not in map(lambda mnt : mnt.mountPoint, dbutils.fs.mounts()):\n  dbutils.fs.mount(\n    source = os.environ['AML_WORKSPACE_DATASETS_SOURCE'],\n    mount_point = basepath,\n    extra_configs = {os.environ['AML_WORKSPACE_DATASETS_SCOPE']:os.environ['AML_WORKSPACE_DATASETS_KEY']})"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"markdown","source":["### Reading the training data\n\nIn this example, I'm using the dataset from Kaggle Gas sensor array under dynamic gas mixture: https://www.kaggle.com/uciml/gas-sensor-array-under-dynamic-gas-mixtures\n\nThis data set contains the acquired time series from 16 chemical sensors exposed to gas mixtures at varying concentration levels. In particular, we generated two gas mixtures: Ethylene and Methane in air, and Ethylene and CO in air. Each measurement was constructed by the continuous acquisition of the 16-sensor array signals for a duration of about 12 hours without interruption. \nThe data set was collected in a gas delivery platform facility at the ChemoSignals Laboratory in the BioCircuits Institute, University of California San Diego. The measurement system platform provides versatility for obtaining the desired concentrations of the chemical substances of interest with high accuracy and in a highly reproducible manner."],"metadata":{}},{"cell_type":"code","source":["# In my case, the file is stored in \nmixture_df = spark.read.parquet(basepath + \"/gas-sensor-mixture/processed/ethylene_methane.parquet/*.parquet\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"markdown","source":["Create some folders to store artifacts"],"metadata":{}},{"cell_type":"code","source":["import os, shutil\n\nmodel_name = \"gbt_methaneconc_ppm\"\nmodel_dbfs = os.path.join(\"/FileStore\", model_name)\ndbutils.fs.mkdirs(model_dbfs)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[3]: True</div>"]}}],"execution_count":5},{"cell_type":"markdown","source":["#### Split dataset in Train and Test sets\nAs usual, we need to split the dataset in a train/test proportions. In this case we are leaving 75% of the dataset for training, and 25% for testing."],"metadata":{}},{"cell_type":"code","source":["train, test = mixture_df.randomSplit([0.75, 0.25])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"markdown","source":["#### Build the model to predict Methaneconc concentration\n\nTree-based ensemble models are powerful estimators which tent to work, on average, prety well. Random Forest Regression is a fairly simple ensemble model that uses a modified tree learning algorithm that selects, at each candidate split in the learning process, a random subset of the features. This process is sometimes called \"feature bagging\". Another tree based ensemble model is Gradient Boosted Trees which uses a different approach called boosting to fit. Boosting reduces error mainly by reducing bias (and also to some extent variance, by aggregating the output from many models).\n\nIn this case we are going to build a model that first creates a vector from all the channels we have data from, and then use such vector to apply a Gradient Boosting Tree. Both steps are gathered together in a Pipeline object"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.regression import GBTRegressor\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml import Pipeline\n\n# Train a Gradient Boosted Trees (GBT) model.\nassembler = VectorAssembler(inputCols=[\"SensorCH\" + str(index) for index in range(1,17)], outputCol=\"features\")\ngbt = GBTRegressor(labelCol=\"Methaneconc_ppm\")\ngbtPipeline = Pipeline(stages=[assembler, gbt])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"markdown","source":["#### Train the model\n\nWe train the pipeline using the fit method from the object"],"metadata":{}},{"cell_type":"code","source":["gbtModel = gbtPipeline.fit(train.drop('Time_seconds', 'Ethyleneconc_ppm'))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":11},{"cell_type":"markdown","source":["#### Evaluate the results for the regression model\n\nWe are considering in this case R2"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.evaluation import RegressionEvaluator\n\npredictions = gbtModel.transform(test)\n\nevaluator = RegressionEvaluator()\nmethaneconc_r2 = evaluator.evaluate(predictions, {evaluator.labelCol:\"Methaneconc_ppm\", evaluator.metricName: \"r2\"})"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":13},{"cell_type":"markdown","source":["#### Save the model in the MLLib format\n\nIn MLLib, a Pipeline object is stored as a folder structure, where each of the steps in the pipeline is stored as a different subfolder in the structure. Inside such subfolder we will find all the information about such step. In order to register and save the model then, we must save it but also zip the entire directory."],"metadata":{}},{"cell_type":"code","source":["gbtModel.write().overwrite().save(model_dbfs)\nmodel_path_drv = shutil.make_archive(base_name=\"/tmp/\"+model_name, format='zip', base_dir=\"/dbfs\"+model_dbfs)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":15},{"cell_type":"markdown","source":["You can now upload to your repository the file stored in model_path_drv. This file is located in the driver node"],"metadata":{}},{"cell_type":"markdown","source":["#### Save the model in the ONNX format"],"metadata":{}},{"cell_type":"code","source":["import tempfile\ntempfile.tempdir = \"/tmp\" # I had to apply this fix in order to get the convert_sparkml to work correctly"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":18},{"cell_type":"code","source":["from onnxmltools import convert_sparkml\nfrom onnxmltools.convert.sparkml.utils import buildInitialTypesSimple\n\nsample_input = test.drop('Time_seconds', 'Ethyleneconc_ppm', 'Methaneconc_ppm') #Dropping unused columns for the model. Only retaining SensorCH01, 02,...\ninitial_types = buildInitialTypesSimple(sample_input) \nonnx_model = convert_sparkml(gbtModel, 'My Sparkml Pipeline', initial_types, spark_session = spark)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">The maximum opset needed by this model is only 1.\n</div>"]}}],"execution_count":19},{"cell_type":"code","source":["with open(os.path.join(\"/tmp/\", \"gbt_methaneconc_ppm.onnx\"), \"wb\") as f:\n    f.write(onnx_model.SerializeToString())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":20},{"cell_type":"markdown","source":["You can now upload the file /tmp/gbt_methaneconc_ppm.onnx. The file is at the driver node"],"metadata":{}},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":22}],"metadata":{"name":"05 - ONNX","notebookId":2721159189289096},"nbformat":4,"nbformat_minor":0}
